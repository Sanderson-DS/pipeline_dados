# 🧠 Pipeline de Dados com API, MongoDB e MySQL

Projeto educacional que demonstra o processo completo de extração, transformação e carregamento de dados (ETL) usando Python. Os dados são coletados de uma API, transformados e salvos em bancos de dados MongoDB e MySQL.

## 🚀 Tecnologias Utilizadas

- Python 3.x
- MongoDB Atlas
- MySQL
- Pandas
- Requests
- PyMongo
- MySQL Connector
- dotenv

## 📁 Estrutura do Projeto

├── data/ # Dados brutos ou processados
├── notebooks/ # Jupyter Notebooks de análise e transformação
├── scripts/ # Scripts Python automatizados (ETL)
├── .gitignore # Arquivos/pastas ignorados pelo Git
├── requirements.txt # Dependências do projeto


## ⚙️ Como executar o projeto

1. Clone o repositório:
   ```bash
   git clone https://github.com/seu-usuario/seu-repositorio.git
   cd seu-repositorio
   
2. Crie um ambiente virtual e ative:
  python -m venv venv
  source venv/bin/activate  # ou .\venv\Scripts\activate no Windows

3.Instale as dependências:
pip install -r requirements.txt

4. Configure suas variáveis de ambiente em um arquivo .env, como:
  MONGO_URI=...
  MYSQL_HOST=...
  MYSQL_USER=...
  MYSQL_PASSWORD=...
  MYSQL_DATABASE=...

5.Execute os notebooks ou scripts conforme desejado.

🧪 Funcionalidades
Conexão segura com MongoDB Atlas e MySQL

Extração de dados via API

Transformação de dados com Pandas

Armazenamento em múltiplos bancos de dados

✍️ Autor
Sanderson Bergmann
LinkedIn - https://www.linkedin.com/in/sanderson-bergmann/




