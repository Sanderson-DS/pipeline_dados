# ğŸ§  Pipeline de Dados com API, MongoDB e MySQL

Projeto educacional que demonstra o processo completo de extraÃ§Ã£o, transformaÃ§Ã£o e carregamento de dados (ETL) usando Python. Os dados sÃ£o coletados de uma API, transformados e salvos em bancos de dados MongoDB e MySQL.

## ğŸš€ Tecnologias Utilizadas

- Python 3.x
- MongoDB Atlas
- MySQL
- Pandas
- Requests
- PyMongo
- MySQL Connector
- dotenv

## ğŸ“ Estrutura do Projeto

â”œâ”€â”€ data/ # Dados brutos ou processados
â”œâ”€â”€ notebooks/ # Jupyter Notebooks de anÃ¡lise e transformaÃ§Ã£o
â”œâ”€â”€ scripts/ # Scripts Python automatizados (ETL)
â”œâ”€â”€ .gitignore # Arquivos/pastas ignorados pelo Git
â”œâ”€â”€ requirements.txt # DependÃªncias do projeto


## âš™ï¸ Como executar o projeto

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/seu-repositorio.git
   cd seu-repositorio
   
2. Crie um ambiente virtual e ative:
  python -m venv venv
  source venv/bin/activate  # ou .\venv\Scripts\activate no Windows

3.Instale as dependÃªncias:
pip install -r requirements.txt

4. Configure suas variÃ¡veis de ambiente em um arquivo .env, como:
  MONGO_URI=...
  MYSQL_HOST=...
  MYSQL_USER=...
  MYSQL_PASSWORD=...
  MYSQL_DATABASE=...

5.Execute os notebooks ou scripts conforme desejado.

ğŸ§ª Funcionalidades
ConexÃ£o segura com MongoDB Atlas e MySQL

ExtraÃ§Ã£o de dados via API

TransformaÃ§Ã£o de dados com Pandas

Armazenamento em mÃºltiplos bancos de dados

âœï¸ Autor
Sanderson Bergmann
LinkedIn - https://www.linkedin.com/in/sanderson-bergmann/




